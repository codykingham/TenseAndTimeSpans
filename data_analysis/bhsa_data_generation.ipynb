{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export BHSA Data for Processing\n",
    "\n",
    "Use Text-Fabric to export a time-expression (timex) dataset and a verb dataset.\n",
    "\n",
    "## Selections for Time Expressions\n",
    "* **Select phrases with the function of `Time`.**\n",
    "    * Exclude phrases that occur in clauses with multiple time-function phrases.\n",
    "    <br><br>\n",
    "* **Features of the phrase**\n",
    "    * lexeme/count of prepositions, substantives, and quantifiers (cardinal numbers).\n",
    "    * part of speech patterns within the phrase\n",
    "    <br><br>\n",
    "* **Features of the enclosing clause**\n",
    "    * domain\n",
    "    * lex and tense of verb if present\n",
    "    * position of phrase in relation to the verb \n",
    "    * position of phrase in relation to the clause\n",
    "    * main vs. subordinate\n",
    "    \n",
    "## Selections for Verbs\n",
    "\n",
    "In order to compare the time phrase dataset with the broader tendencies of verbs in the Hebrew Bible, another export contains:\n",
    "* **Features of verbs in the HB**\n",
    "    * verb must be in a predicate phrase\n",
    "    * tense and lexeme\n",
    "    <br><br>\n",
    "* **Features of the enclosing clause**\n",
    "    * domain\n",
    "    * position of verb's phrase in relation to the clause\n",
    "    * main vs. subordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import sys, path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put custom functions in path\n",
    "if __name__ == '__main__' and __package__ is None:\n",
    "    sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.0.9\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "114 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='~/github/etcbc/bhsa/tf', modules='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B chapter              from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B verse                from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.17s B function             from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.05s B kind                 from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.21s B pdp                  from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.46s B typ                  from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.39s B rela                 from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.17s B ls                   from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.03s B domain               from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.21s B vt                   from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.23s B lex                  from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.54s B number               from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 108 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "    11s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "                 book chapter verse\n",
    "                 function kind\n",
    "                 pdp typ rela ls\n",
    "                 domain vt lex\n",
    "                 number\n",
    "              ''')\n",
    "\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom function to id weqetal verbs and for subject isolation\n",
    "from my_functions.verbs import is_weqt \n",
    "from my_functions.phrases import is_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Time Phrases\n",
    "\n",
    "The time phrase cannot occur inside a clause with more than 1 time phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3826 time expressions ready for proccessing...\n"
     ]
    }
   ],
   "source": [
    "timexes = []\n",
    "\n",
    "for phrase in F.function.s('Time'):\n",
    "    \n",
    "    # skip phrases with >1 TP in its clause\n",
    "    clause = L.u(phrase, otype='clause')[0]\n",
    "    phrase_functs = [F.function.v(ph) for ph in L.d(clause, otype='phrase')]\n",
    "    if phrase_functs.count('Time') > 1:\n",
    "        continue\n",
    "        \n",
    "    # append the relevant data\n",
    "    timexes.append((clause, phrase))\n",
    "\n",
    "print(len(timexes), 'time expressions ready for proccessing...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Time Phrases\n",
    "\n",
    "Retrieve the phrase/clause level information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3826 rows ready for export...\n",
      "\n",
      "sample:  ['Genesis', 19, 34, 429263, 656759, '>MC', 'ø', 0, 'ø', 0, 'ø', 0, 'advb', 'Q', 'CKB[', 'perf', 2, 3, 'I']\n"
     ]
    }
   ],
   "source": [
    "# header for csv export & and how data should be assembled\n",
    "header = ['book', 'chapter', 'verse', 'clause.n', 'phrase.n', \n",
    "          'phrase.trans', 'preps', 'num.preps', 'subs',\n",
    "          'num.subs', 'quants', 'num.quants', 'pdp.pattern',\n",
    "          'domain', 'verb.lex', 'verb.tense', 'position.at.vb',\n",
    "          'position.at.cl', 'cl.dependency']\n",
    "\n",
    "# put data here for csv export\n",
    "rows = []\n",
    "\n",
    "# get row data per time phrase\n",
    "for clause_n, phrase_n in timexes:\n",
    "\n",
    "    book, chapter, verse = T.sectionFromNode(clause_n)\n",
    "        \n",
    "        \n",
    "    # // phrase data //\n",
    "    \n",
    "    # transcription\n",
    "    ph_words = L.d(phrase_n, otype='word')\n",
    "    ph_trans = T.text(ph_words, fmt='lex-trans-plain').strip()\n",
    "    \n",
    "    # substantives\n",
    "    subs = [F.lex.v(w) for w in ph_words if is_subs(w)] # w/ custom funct. is_subs()\n",
    "    num_subs = len(subs)\n",
    "    subs_txt = '|'.join(subs) or 'ø'\n",
    "    \n",
    "    # prepositions\n",
    "    preps = [F.lex.v(w) for w in ph_words if F.pdp.v(w) == 'prep']\n",
    "    num_preps = len(preps)\n",
    "    preps_txt = '|'.join(preps) or 'ø'\n",
    "    \n",
    "    # quantities (card == \"cardinal number\")\n",
    "    quants = [F.lex.v(w) for w in ph_words if F.ls.v(w) == 'card']\n",
    "    num_quants = len(quants)\n",
    "    quants_txt = '|'.join(quants) or 'ø'\n",
    "    \n",
    "    # phrase dep. part of speech pattern\n",
    "    pdp_pattern = '-'.join(F.pdp.v(w) for w in L.d(phrase_n, otype='word'))\n",
    "    \n",
    "    \n",
    "    # // clause data // \n",
    "    \n",
    "    domain = F.domain.v(clause_n)\n",
    "        \n",
    "    # get verb lex and its tense\n",
    "    pred_functs = {'Pred', 'PreO', 'PreS', 'PtcO'}\n",
    "    verb = [word for phrase in L.d(clause_n, otype='phrase')\n",
    "               for word in L.d(phrase, otype='word')\n",
    "               if F.pdp.v(word) == 'verb' \n",
    "               and F.function.v(phrase) in pred_functs\n",
    "           ]\n",
    "    if verb:\n",
    "        verb_n = verb[0]\n",
    "        verb_lex = F.lex.v(verb_n)\n",
    "        verb_tense = F.vt.v(verb_n) if not is_weqt(verb_n) else 'weqt' # + hacked weqetal\n",
    "    else:\n",
    "        verb_lex = 'ø'\n",
    "        verb_tense = 'ø'\n",
    "        \n",
    "    # time-phrase position to verb\n",
    "    pos_at_vb = 1 if phrase_n < verb_n else 2\n",
    "    pos_at_cl = F.number.v(phrase_n)\n",
    "    \n",
    "    # clause dependency\n",
    "    cl_dependency = 'I' if F.rela.v(clause_n) == 'NA' else 'D'\n",
    "    \n",
    "    \n",
    "    # // ship it //\n",
    "    \n",
    "    # package the row and append it\n",
    "    row = [book, chapter, verse, clause_n, phrase_n,\n",
    "           ph_trans, preps_txt, num_preps, subs_txt,\n",
    "           num_subs, quants_txt, num_quants, pdp_pattern,\n",
    "           domain, verb_lex, verb_tense, pos_at_vb,\n",
    "           pos_at_cl, cl_dependency]\n",
    "           \n",
    "    rows.append(row)\n",
    "    \n",
    "print(len(rows), 'rows ready for export...')\n",
    "print()\n",
    "print('sample: ', rows[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Timex Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the .csv\n",
    "with open('time_phrases.csv', 'w') as outfile:\n",
    "    \n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect and Process Verb Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63522 rows ready for export...\n",
      "\n",
      "sample:  ['Genesis', 2, 15, 427730, 953, 'NWX[', 'wayq', 'N', 2, 'I']\n"
     ]
    }
   ],
   "source": [
    "header = ['book', 'chapter', 'verse', 'clause.n', \n",
    "          'verb.n', 'lexeme', 'tense', 'domain', \n",
    "          'position.at.cl', 'cl.dependency']\n",
    "\n",
    "rows = []\n",
    "\n",
    "# gather verb data\n",
    "for verb in F.pdp.s('verb'):\n",
    "\n",
    "    book, chapter, verse = T.sectionFromNode(verb)\n",
    "    \n",
    "    # skip verbs without a predicate phrase function\n",
    "    phrase = L.u(verb, otype='phrase')[0]\n",
    "    pred_functs = {'Pred', 'PreO', 'PreS', 'PtcO'}\n",
    "    if F.function.v(phrase) not in pred_functs:\n",
    "        continue\n",
    "        \n",
    "    # verb level data\n",
    "    tense = F.vt.v(verb)\n",
    "    lex = F.lex.v(verb)\n",
    "    \n",
    "    # clause level data\n",
    "    clause_n = L.u(verb, otype='clause')[0]\n",
    "    domain = F.domain.v(clause_n)\n",
    "    pos_at_cl = F.number.v(phrase)\n",
    "    cl_dependency = 'I' if F.rela.v(clause_n) == 'NA' else 'D'\n",
    "\n",
    "    # package and save\n",
    "    row = [book, chapter, verse, clause_n, verb, \n",
    "           lex, tense, domain, pos_at_cl, \n",
    "           cl_dependency]\n",
    "    \n",
    "    rows.append(row)\n",
    "    \n",
    "print(len(rows), 'rows ready for export...')\n",
    "print()\n",
    "print('sample: ', rows[124])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Tense Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verbs.csv', 'w') as outfile:\n",
    "    \n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
