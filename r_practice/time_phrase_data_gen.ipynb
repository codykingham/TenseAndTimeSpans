{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export TF Data from BHSAc for R Processing\n",
    "\n",
    "I will export specifically data on time phrase markers. Aramaic is excluded.\n",
    "\n",
    "dataset contains:\n",
    "\n",
    "book&nbsp;|&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric\n",
    "from os import sys, path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put custom functions in path\n",
    "if __name__ == '__main__' and __package__ is None:\n",
    "    sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.0.9\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "113 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='~/github/etcbc/bhsa/tf', modules='c')\n",
    "TF2016 = Fabric(locations='~/github/etcbc/bhsa/tf', modules='2016', silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.02s B book                 from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.02s B chapter              from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B verse                from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.09s B function             from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.03s B kind                 from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.16s B pdp                  from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.27s B typ                  from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.27s B rela                 from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.15s B ls                   from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.02s B domain               from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.15s B vt                   from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.17s B lex                  from /Users/Cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 108 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  7.73s All features loaded/computed - for details use loadLog()\n",
      "  0.00s loading features ...\n",
      "   |     0.09s B function             from /Users/Cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.03s B kind                 from /Users/Cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.00s Feature overview: 102 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  6.16s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "# load c data\n",
    "api = TF.load('''\n",
    "                 book chapter verse\n",
    "                 function kind\n",
    "                 pdp typ rela ls\n",
    "                 domain vt lex\n",
    "              ''')\n",
    "\n",
    "api.makeAvailableIn(globals())\n",
    "\n",
    "\n",
    "e4c = TF2016.load('function kind') # load 2016 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom function to id weqetal verbs and for subject isolation\n",
    "from my_functions.verbs import is_weqt \n",
    "from my_functions.substantives import is_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 366\n",
      "2016 160\n",
      "difference: 206\n"
     ]
    }
   ],
   "source": [
    "# versions check\n",
    "# I was unsure about the difference between c and 2016 based on Dirk Roorda's chart (see below)\n",
    "# https://github.com/ETCBC/bhsa/blob/master/programs/versionPhrases.ipynb\n",
    "# As shown below, most changes in Time-funct. phrases came from clauses without predication\n",
    "\n",
    "# time phrases in c WP clauses (\"without predication\")\n",
    "time_phrases_c = [phrase for phrase in F.function.s('Time')\n",
    "                     if F.kind.v(L.u(phrase, otype='clause')[0]) == 'WP'\n",
    "                 ]\n",
    "# time phrases in 2016\n",
    "time_phrases_4c = [phrase for phrase in e4c.F.function.s('Time')\n",
    "                       if e4c.F.kind.v(e4c.L.u(phrase, otype='clause')[0]) == 'WP'\n",
    "                  \n",
    "                  ]\n",
    "\n",
    "print('c', len(time_phrases_c))\n",
    "print('2016', len(time_phrases_4c))\n",
    "print('difference:', len(time_phrases_c) - len(time_phrases_4c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that 206 changes between 2016 and now (Oct 2017) occurred within clauses without predication (`WP`). 206 time phrases were added into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3245 results ready...\n"
     ]
    }
   ],
   "source": [
    "time_phrase_data = '''\n",
    "\n",
    "clause kind=VC\n",
    "    phrase function=Time\n",
    "    \n",
    "    phrase function=Pred|PreO|PreS|PtcO\n",
    "        word pdp=verb\n",
    "'''\n",
    "\n",
    "S.study(time_phrase_data, silent=True)\n",
    "\n",
    "results = sorted(set(result for result in S.fetch()))\n",
    "\n",
    "print(len(results), 'results ready...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(428158, 653363, 653366, 3253),\n",
       " (428158, 653364, 653366, 3253),\n",
       " (428158, 653365, 653366, 3253),\n",
       " (428202, 653519, 653516, 3612),\n",
       " (428204, 653527, 653528, 3650)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# be aware that there are some repeated results due to multiple time phrases within a single clause\n",
    "\n",
    "already_encountered = set()\n",
    "\n",
    "double_results = []\n",
    "\n",
    "# get doubled results\n",
    "for r in results:\n",
    "    \n",
    "    if r[0] in already_encountered:\n",
    "        double_results.append(r)\n",
    "    \n",
    "    else:\n",
    "        already_encountered.add(r[0])\n",
    "    \n",
    "\n",
    "# see the repeated results below where the clause is the same but the phrase matches are different.\n",
    "double_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3245 rows ready for export...\n",
      "sample:  ['Genesis', 18, 14, 429009, 656022, 'Q', 2, 'impf', 1, 'K', 1, '<T/', 0, 'NA', 'prep-art-subs-adjv']\n"
     ]
    }
   ],
   "source": [
    "# put csv data here\n",
    "rows = []\n",
    "\n",
    "# get row data per time phrase (there will be some repeated clauses due to plural time phrases)\n",
    "for r in results:\n",
    "    \n",
    "    # specify result nodes\n",
    "    clause_n, time_n, pred_n, verb_n = r  \n",
    "    time_words = L.d(time_n, otype='word')\n",
    "    \n",
    "    # (1) section data\n",
    "    book, chapter, verse = T.sectionFromNode(clause_n)\n",
    "        \n",
    "    # (2) clause-level data\n",
    "    domain = F.domain.v(clause_n)\n",
    "    num_time_phrases = len([phrase for phrase in L.d(clause_n, otype='phrase')\n",
    "                               if F.function.v(phrase) == 'Time'])\n",
    "    \n",
    "    # (3) word-level data\n",
    "    # tense\n",
    "    verb_tense = F.vt.v(verb_n) if not is_weqt(verb_n) else 'weqt' # + hacked weqetal\n",
    "    \n",
    "    # substantives\n",
    "    subs = [F.lex.v(w) for w in time_words if is_subs(w)]\n",
    "    num_subs = len(subs)\n",
    "    subs_txt = '|'.join(subs) or 'NA'\n",
    "    \n",
    "    # prepositions\n",
    "    preps = [F.lex.v(w) for w in time_words if F.pdp.v(w) == 'prep']\n",
    "    num_preps = len(preps)\n",
    "    preps_txt = '|'.join(preps) or 'NA'\n",
    "    \n",
    "    # quantities (card == \"cardinal number\")\n",
    "    quants = [F.lex.v(w) for w in time_words if F.ls.v(w) == 'card']\n",
    "    num_quants = len(quants)\n",
    "    quants_txt = '|'.join(quants) or 'NA'\n",
    "    \n",
    "    # phrase dep. part of speech\n",
    "    pdp_tags = '-'.join(F.pdp.v(w) for w in L.d(time_n, otype='word'))\n",
    "    \n",
    "    # package the row and append it\n",
    "    row = [book, chapter, verse, clause_n, time_n, domain, num_time_phrases, verb_tense,\n",
    "           num_preps, preps_txt, num_subs, subs_txt, num_quants, quants_txt, pdp_tags]\n",
    "    \n",
    "    rows.append(row)\n",
    "    \n",
    "print(len(rows), 'rows ready for export...')\n",
    "print('sample: ', rows[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the .csv\n",
    "\n",
    "header = ['book', 'chapter', 'verse', 'clause.n', 'time.n', 'domain', 'num.time.phrases',\n",
    "          'verb.tense', 'num.preps', 'preps', 'num.subs', 'subs', 'num.quants', 'quants', 'pdp.tags']\n",
    "\n",
    "with open('time_phrases.csv', 'w') as outfile:\n",
    "    \n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'טֶ֣רֶם '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(L.d(651923, otype='word'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
